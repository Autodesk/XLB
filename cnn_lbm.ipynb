{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:05:22.533994Z",
     "start_time": "2024-06-18T07:05:21.567514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax\n",
    "from jax.experimental.multihost_utils import process_allgather\n",
    "from termcolor import colored\n",
    "from src.base import LBMExternalForce, LBMBase\n",
    "from src.utils import *\n",
    "from src.boundary_conditions import *\n",
    "from src.models import BGKSim, KBCSim\n",
    "from src.lattice import LatticeD2Q9\n",
    "import jaxlib\n",
    "# Use 8 CPU devices\n",
    "# os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "jax.config.update('jax_enable_x64', True)\n"
   ],
   "id": "5f01967c372d1b78",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-18T07:05:22.540118Z",
     "start_time": "2024-06-18T07:05:22.534987Z"
    }
   },
   "source": [
    "class Cylinder(BGKSim):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def set_boundary_conditions(self):\n",
    "        # Define the cylinder surface\n",
    "        coord = np.array([(i, j) for i in range(self.nx) for j in range(self.ny)])\n",
    "        xx, yy = coord[:, 0], coord[:, 1]\n",
    "        cx, cy = 2.*_diam, 2.*_diam\n",
    "        cylinder = (xx - cx)**2 + (yy-cy)**2 <= (_diam/2.)**2\n",
    "        cylinder = coord[cylinder]\n",
    "        implicit_distance = np.reshape((xx - cx)**2 + (yy-cy)**2 - (_diam/2.)**2, (self.nx, self.ny))\n",
    "        self.BCs.append(InterpolatedBounceBackBouzidi(tuple(cylinder.T), implicit_distance, self.gridInfo, self.precisionPolicy))\n",
    "\n",
    "        # Outflow BC\n",
    "        outlet = self.boundingBoxIndices['right']\n",
    "        rho_outlet = np.ones((outlet.shape[0], 1), dtype=self.precisionPolicy.compute_dtype)\n",
    "        self.BCs.append(ExtrapolationOutflow(tuple(outlet.T), self.gridInfo, self.precisionPolicy))\n",
    "        # self.BCs.append(ZouHe(tuple(outlet.T), self.gridInfo, self.precisionPolicy, 'pressure', rho_outlet))\n",
    "\n",
    "        # Inlet BC\n",
    "        inlet = self.boundingBoxIndices['left']\n",
    "        rho_inlet = np.ones((inlet.shape[0], 1), dtype=self.precisionPolicy.compute_dtype)\n",
    "        vel_inlet = np.zeros(inlet.shape, dtype=self.precisionPolicy.compute_dtype)\n",
    "        yy_inlet = yy.reshape(self.nx, self.ny)[tuple(inlet.T)]\n",
    "        vel_inlet[:, 0] = poiseuille_profile(yy_inlet,\n",
    "                                             yy_inlet.min(),\n",
    "                                             yy_inlet.max()-yy_inlet.min(), 3.0 / 2.0 * _prescribed_vel)\n",
    "        self.BCs.append(Regularized(tuple(inlet.T), self.gridInfo, self.precisionPolicy, 'velocity', vel_inlet))\n",
    "\n",
    "        # No-slip BC for top and bottom\n",
    "        wall = np.concatenate([self.boundingBoxIndices['top'], self.boundingBoxIndices['bottom']])\n",
    "        vel_wall = np.zeros(wall.shape, dtype=self.precisionPolicy.compute_dtype)\n",
    "        self.BCs.append(Regularized(tuple(wall.T), self.gridInfo, self.precisionPolicy, 'velocity', vel_wall))\n",
    "\n",
    "    def output_data(self, **kwargs):\n",
    "        self.saved_data.append({\n",
    "            'rho':process_allgather(kwargs['rho']),\n",
    "            'u':process_allgather(kwargs['u']),\n",
    "            'timestep':kwargs['timestep'],\n",
    "        })\n",
    "        # 1:-1 to remove boundary voxels (not needed for visualization when using bounce-back)\n",
    "\n",
    "# Helper function to specify a parabolic poiseuille profile\n",
    "poiseuille_profile  = lambda x,x0,d,umax: np.maximum(0.,4.*umax/(d**2)*((x-x0)*d-(x-x0)**2))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:05:22.600961Z",
     "start_time": "2024-06-18T07:05:22.541032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "  \"\"\"Defines a convolutional block with activation and normalization.\"\"\"\n",
    "  features: int\n",
    "  kernel_size: int = (3,3)\n",
    "  strides: int = 1\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs):\n",
    "    x = nn.Conv(self.features, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(inputs)\n",
    "    x = nn.BatchNorm(use_running_average=True)(x)\n",
    "    x = nn.relu(x)\n",
    "    return x\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "  \"\"\"Downsamples feature maps through convolutions and pooling.\"\"\"\n",
    "  features: int\n",
    "  pool_factor: int = 2\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = ConvBlock(self.features)(x)\n",
    "    x = ConvBlock(self.features)(x)\n",
    "    return x\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "  \"\"\"Upsamples feature maps and concatenates with features from the contracting path.\"\"\"\n",
    "  features: int\n",
    "  up_factor: int = 2\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = ConvBlock(self.features)(x)\n",
    "    x = ConvBlock(self.features)(x)\n",
    "    x = nn.ConvTranspose(self.features, kernel_size=(2, 2), strides=self.up_factor, padding='VALID')(x)\n",
    "    return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "  \"\"\"UNet architecture with contracting and expanding paths.\"\"\"\n",
    "  features_start: int = 64\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    input_shape = x.shape\n",
    "    # Contracting path\n",
    "    down1 = DownBlock(self.features_start * 2)(x)\n",
    "    down1_max_pooled = nn.max_pool(down1, window_shape=(2, 2), strides=(2, 2))\n",
    "    down2 = DownBlock(self.features_start * 4)(down1_max_pooled)\n",
    "    down2_max_pooled = nn.max_pool(down2, window_shape=(2, 2), strides=(2, 2))\n",
    "    down3 = DownBlock(self.features_start * 8)(down2_max_pooled)\n",
    "    down3_max_pooled = nn.max_pool(down3, window_shape=(2, 2), strides=(2, 2))\n",
    "    down4 = DownBlock(self.features_start * 16)(down3_max_pooled)\n",
    "    down4_max_pooled = nn.max_pool(down4, window_shape=(2, 2), strides=(2, 2))\n",
    "    \n",
    "    # Expanding path with concatenation\n",
    "    up1 = UpBlock(self.features_start * 16)(down4_max_pooled)\n",
    "    down4_sliced = jax.lax.slice(down4, (4, 4, 0),(down4.shape[0]-4, down4.shape[1]-4, down4.shape[2]))\n",
    "    up1_concatenated = jax.lax.concatenate([down4_sliced, up1], dimension=2)\n",
    "    up2 = UpBlock(self.features_start * 4)(up1_concatenated)\n",
    "    down3_sliced = jax.lax.slice(down3, (4, 4, 0), (down3.shape[0]-4, down3.shape[1]-4, down3.shape[2]))\n",
    "    up2_concatenated = jax.lax.concatenate([down3_sliced, up2], dimension=2)\n",
    "    up3 = UpBlock(self.features_start * 2)(up2_concatenated)\n",
    "    print(up3.shape)\n",
    "    return up3\n",
    "  \n",
    "class SimpleNet(nn.Module):\n",
    "    features: int = 32\n",
    "    kernel_size: int = (5, 5)\n",
    "    strides: int = 1\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # x = nn.Conv(self.features, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(x)\n",
    "        # x = nn.leaky_relu(x)\n",
    "        # x = nn.Conv(self.features, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(x)\n",
    "        # x = nn.leaky_relu(x)\n",
    "        x = nn.Conv(self.features, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "        x = nn.Dense(self.features)(x)\n",
    "        x = nn.Conv(2, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(x)\n",
    "        return x\n"
   ],
   "id": "d0bd9ac354a8c2c3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:05:24.526018Z",
     "start_time": "2024-06-18T07:05:22.602391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from clu import metrics\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "from flax import struct                # Flax dataclasses\n",
    "import optax                           # Common loss functions and optimizers\n",
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "  accuracy: metrics.Accuracy\n",
    "  loss: metrics.Average.from_output('loss')\n",
    "class TrainState(train_state.TrainState):\n",
    "  metrics: Metrics\n",
    "\n",
    "def create_train_state(module, rng, learning_rate, momentum):\n",
    "  \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "  params = module.init(rng, jnp.ones([1, 440, 82, 2]))['params'] # initialize parameters by passing a template image\n",
    "  tx = optax.sgd(learning_rate, momentum)\n",
    "  return TrainState.create(\n",
    "      apply_fn=module.apply, params=params, tx=tx,\n",
    "      metrics=Metrics.empty())\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, ref_data, low_res_lbm_solver: LBMBase):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  frame_idx = 0\n",
    "  input_frame=ref_data[frame_idx]\n",
    "  ref_frame=ref_data[frame_idx+1]\n",
    "  ts = input_frame['timestep']\n",
    "  rho = input_frame['rho']\n",
    "  u = input_frame['u']\n",
    "  f = low_res_lbm_solver.equilibrium(rho, u, False)\n",
    "  low_res_lbm_solver.run_step(ts+1, ts, f)\n",
    "  output_frame=low_res_lbm_solver.saved_data[0]\n",
    "  def loss_fn(params):\n",
    "    correction = state.apply_fn({'params': params}, low_res_lbm_solver.saved_data[0]['u'])\n",
    "    loss = optax.l2_loss(output_frame['u']+correction, ref_frame['u'])\n",
    "    return loss\n",
    "  grad_fn = jax.grad(loss_fn)\n",
    "  grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state\n",
    "\n",
    "@jax.jit\n",
    "def pred_step(state, batch):\n",
    "  return state.apply_fn({'params': state.params}, batch)\n",
    "init_rng = jax.random.key(0)\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "from tqdm import tqdm\n",
    "my_unet = SimpleNet()\n",
    "state = create_train_state(my_unet, init_rng, learning_rate, momentum)"
   ],
   "id": "643d5ef163477022",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:05:24.532478Z",
     "start_time": "2024-06-18T07:05:24.526913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BGKSimForce(LBMExternalForce):\n",
    "    \"\"\"\n",
    "    BGK simulation class.\n",
    "\n",
    "    This class implements the Bhatnagar-Gross-Krook (BGK) approximation for the collision step in the Lattice Boltzmann Method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def collision(self, f, feq, rho, u):\n",
    "        \"\"\"\n",
    "        BGK collision step for lattice.\n",
    "\n",
    "        The collision step is where the main physics of the LBM is applied. In the BGK approximation, \n",
    "        the distribution function is relaxed towards the equilibrium distribution function.\n",
    "        \"\"\"\n",
    "        fneq = f - feq\n",
    "        fout = f - self.omega * fneq\n",
    "        return self.precisionPolicy.cast_to_output(fout)\n",
    "\n",
    "class CylinderForce(BGKSimForce):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def set_boundary_conditions(self):\n",
    "        # Define the cylinder surface\n",
    "        coord = np.array([(i, j) for i in range(self.nx) for j in range(self.ny)])\n",
    "        xx, yy = coord[:, 0], coord[:, 1]\n",
    "        cx, cy = 2.*_diam, 2.*_diam\n",
    "        cylinder = (xx - cx)**2 + (yy-cy)**2 <= (_diam/2.)**2\n",
    "        cylinder = coord[cylinder]\n",
    "        implicit_distance = np.reshape((xx - cx)**2 + (yy-cy)**2 - (_diam/2.)**2, (self.nx, self.ny))\n",
    "        self.BCs.append(InterpolatedBounceBackBouzidi(tuple(cylinder.T), implicit_distance, self.gridInfo, self.precisionPolicy))\n",
    "\n",
    "        # Outflow BC\n",
    "        outlet = self.boundingBoxIndices['right']\n",
    "        rho_outlet = np.ones((outlet.shape[0], 1), dtype=self.precisionPolicy.compute_dtype)\n",
    "        self.BCs.append(ExtrapolationOutflow(tuple(outlet.T), self.gridInfo, self.precisionPolicy))\n",
    "        # self.BCs.append(ZouHe(tuple(outlet.T), self.gridInfo, self.precisionPolicy, 'pressure', rho_outlet))\n",
    "\n",
    "        # Inlet BC\n",
    "        inlet = self.boundingBoxIndices['left']\n",
    "        rho_inlet = np.ones((inlet.shape[0], 1), dtype=self.precisionPolicy.compute_dtype)\n",
    "        vel_inlet = np.zeros(inlet.shape, dtype=self.precisionPolicy.compute_dtype)\n",
    "        yy_inlet = yy.reshape(self.nx, self.ny)[tuple(inlet.T)]\n",
    "        vel_inlet[:, 0] = poiseuille_profile(yy_inlet,\n",
    "                                             yy_inlet.min(),\n",
    "                                             yy_inlet.max()-yy_inlet.min(), 3.0 / 2.0 * _prescribed_vel)\n",
    "        self.BCs.append(Regularized(tuple(inlet.T), self.gridInfo, self.precisionPolicy, 'velocity', vel_inlet))\n",
    "\n",
    "        # No-slip BC for top and bottom\n",
    "        wall = np.concatenate([self.boundingBoxIndices['top'], self.boundingBoxIndices['bottom']])\n",
    "        vel_wall = np.zeros(wall.shape, dtype=self.precisionPolicy.compute_dtype)\n",
    "        self.BCs.append(Regularized(tuple(wall.T), self.gridInfo, self.precisionPolicy, 'velocity', vel_wall))\n",
    "\n",
    "    def output_data(self, **kwargs):\n",
    "        self.saved_data.append(kwargs['u'])\n",
    "        # 1:-1 to remove boundary voxels (not needed for visualization when using bounce-back)\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def get_force(self, f_postcollision, feq, rho, u):\n",
    "        return state.apply_fn({'params': state.params}, u)"
   ],
   "id": "a2c80e8ddd009680",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:15:31.108725Z",
     "start_time": "2024-06-18T07:15:31.105133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_sim_dataset(diam, t_start, t_end, output_stride, output_offset):\n",
    "    global _diam\n",
    "    global _prescribed_vel\n",
    "    _diam = diam\n",
    "    precision = 'f64/f64'\n",
    "    # diam_list = [10, 20, 30, 40, 60, 80]\n",
    "    scale_factor = 80 / diam\n",
    "    prescribed_vel = 0.003 * scale_factor\n",
    "    _prescribed_vel = prescribed_vel\n",
    "    lattice = LatticeD2Q9(precision)\n",
    "\n",
    "    nx = int(22*diam)\n",
    "    ny = int(4.1*diam)\n",
    "\n",
    "    Re = 100.0\n",
    "    visc = prescribed_vel * diam / Re\n",
    "    omega = 1.0 / (3. * visc + 0.5)\n",
    "    kwargs = {\n",
    "        'lattice': lattice,\n",
    "        'omega': omega,\n",
    "        'nx': nx,\n",
    "        'ny': ny,\n",
    "        'nz': 0,\n",
    "        'precision': precision,\n",
    "        'return_fpost': True    # Need to retain fpost-collision for computation of lift and drag\n",
    "    }\n",
    "    # characteristic time\n",
    "    tc = prescribed_vel/diam\n",
    "    if t_end < int(100//tc):\n",
    "        print(colored(\"WARNING: timestep_end is too small, Karman flow may not appear. Recommend value is {}\".format(int(100//tc)), \"red\"))\n",
    "    sim = Cylinder(**kwargs)\n",
    "    return sim.run_batch_generator(t_end, t_start, output_offset, output_stride, generator_size=1000)\n",
    "    # return sim.saved_data\n",
    "\n",
    "def generate_sim_dataset_with_profile(diam, t_start, t_end, output_stride, output_offset):\n",
    "    with jax.profiler.trace(\"/tmp/tensorboard\"):\n",
    "        generated_data = generate_sim_dataset(diam, t_start, t_end, output_stride, output_offset)\n",
    "        jax.profiler.save_device_memory_profile(\"memory.prof\")\n",
    "    return generated_data"
   ],
   "id": "33fcbd1555db15ba",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-18T07:15:45.716613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_batched_data(batched_data, seq_num):\n",
    "    output_np_data = {\n",
    "        'timestep' :[],\n",
    "        'u': [],\n",
    "        'rho': []\n",
    "    }\n",
    "    for frame in batched_data:\n",
    "        output_np_data['timestep'].append(frame['timestep'])\n",
    "        output_np_data['u'].append(frame['u'])\n",
    "        output_np_data['rho'].append(frame['rho'])\n",
    "    output_np_data['timestep'] = np.array(output_np_data['timestep'])\n",
    "    output_np_data['u'] = np.stack(output_np_data['u'], axis=0)\n",
    "    output_np_data['rho'] = np.stack(output_np_data['rho'], axis=0)\n",
    "    np.savez_compressed(\"./data/batched_ref_data_{}.npz\".format(seq_num), timestep=output_np_data['timestep'], u=output_np_data['u'], rho=output_np_data['rho'])\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=5) as t:\n",
    "    tasks = []\n",
    "    seq = 0\n",
    "    for batched_data in generate_sim_dataset(80, 0, 50000, 1, 40000):\n",
    "        tasks.append(t.submit(process_batched_data, batched_data, seq))\n",
    "        seq += 1"
   ],
   "id": "d27b5c0ba8a1ca75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mWARNING: timestep_end is too small, Karman flow may not appear. Recommend value is 2666666\u001B[0m\n",
      "\u001B[32m**** Simulation Parameters for Cylinder ****\u001B[0m\n",
      "            \u001B[34mParameter\u001B[0m | \u001B[33mValue\u001B[0m\n",
      "--------------------------------------------------\n",
      "                \u001B[34mOmega\u001B[0m | \u001B[33m1.971608832807571\u001B[0m\n",
      "     \u001B[34mGrid Points in X\u001B[0m | \u001B[33m1760\u001B[0m\n",
      "     \u001B[34mGrid Points in Y\u001B[0m | \u001B[33m328\u001B[0m\n",
      "     \u001B[34mGrid Points in Z\u001B[0m | \u001B[33m0\u001B[0m\n",
      "       \u001B[34mDimensionality\u001B[0m | \u001B[33m2\u001B[0m\n",
      "     \u001B[34mPrecision Policy\u001B[0m | \u001B[33mf64/f64\u001B[0m\n",
      "         \u001B[34mLattice Type\u001B[0m | \u001B[33mD2Q9\u001B[0m\n",
      "      \u001B[34mCheckpoint Rate\u001B[0m | \u001B[33m0\u001B[0m\n",
      " \u001B[34mCheckpoint Directory\u001B[0m | \u001B[33m./checkpoints\u001B[0m\n",
      "  \u001B[34mDownsampling Factor\u001B[0m | \u001B[33m1\u001B[0m\n",
      "      \u001B[34mPrint Info Rate\u001B[0m | \u001B[33m100\u001B[0m\n",
      "             \u001B[34mI/O Rate\u001B[0m | \u001B[33m0\u001B[0m\n",
      "        \u001B[34mCompute MLUPS\u001B[0m | \u001B[33mFalse\u001B[0m\n",
      "   \u001B[34mRestore Checkpoint\u001B[0m | \u001B[33mFalse\u001B[0m\n",
      "              \u001B[34mBackend\u001B[0m | \u001B[33mgpu\u001B[0m\n",
      "    \u001B[34mNumber of Devices\u001B[0m | \u001B[33m1\u001B[0m\n",
      "Time to create the grid mask: 0.10543131828308105\n",
      "Time to create the local masks and normal arrays: 0.07634806632995605\n",
      "WARNING: Default initial conditions assumed: density = 1, velocity = 0\n",
      "         To set explicit initial density and velocity, use self.initialize_macroscopic_fields.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 25374/50001 [03:18<03:12, 128.07it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:10:29.011815Z",
     "start_time": "2024-06-18T07:10:29.004496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_data(data, imgs=20, field='u'):\n",
    "    fig, axs = plt.subplots(1, imgs, figsize=(32, 10))\n",
    "    max_val = data[0]['u'][np.where(data[0]['u'] == data[0]['u'].max())]\n",
    "    min_val = data[0]['u'][np.where(data[0]['u'] == data[0]['u'].min())]\n",
    "    for i in range(imgs):\n",
    "        img = (data[i*(len(data)//imgs)][field] - min_val)/(max_val - min_val)\n",
    "        img = np.concatenate((img, np.zeros((img.shape[0], img.shape[1], 1))), axis=2)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].set_title(\"T={}\".format(data[i*(len(data)//imgs)]['timestep']))\n",
    "def inspect_data(data):\n",
    "    print(colored(\"*** Data Summary ***\", \"red\"))\n",
    "    if len(data)==1:\n",
    "        print(colored(\"Single frame at timestep: {}\".format(data[0]['timestep']), \"green\"))\n",
    "        return\n",
    "    else:\n",
    "        print(colored(\"Timestep: first frame at T={} - last frame at T={}\".format(data[0]['timestep'], data[-1]['timestep']), 'blue'))\n",
    "        print(colored(\"Timestep stride: {}\".format(data[1]['timestep']-data[0]['timestep']), 'blue'))\n",
    "    print(colored(\"Frame attributes:\", 'blue'))\n",
    "    for i in data[0].keys():\n",
    "        print(colored('\\t{}'.format(i), 'green'), end=\" \")\n",
    "        if data[0][i] is None:\n",
    "            print(None)\n",
    "        elif type(data[0][i])==np.ndarray:\n",
    "            print(\"numpy array shape: {}\".format(data[0][i].shape))\n",
    "        elif type(data[0][i])==jaxlib.xla_extension.ArrayImpl:\n",
    "            print(\"jax array shape: {}\".format(data[0][i].shape))\n",
    "        elif type(data[0][i])==int:\n",
    "            print(\"int\")\n",
    "        else:\n",
    "            print(type(data[0][i]))\n",
    "def read_data():\n",
    "    res_data = {\n",
    "        'timestep':[],\n",
    "        'rho':[],\n",
    "        'u':[]\n",
    "    }\n",
    "    total_batch = 1\n",
    "    for i in tqdm(range(total_batch)):\n",
    "        loaded_data = np.load('./data/ref_data_{}.npz'.format(i))\n",
    "        res_data['timestep'].append(loaded_data['timestep'])\n",
    "        res_data['rho'].append(loaded_data['rho'])\n",
    "        res_data['u'].append(loaded_data['u'])\n",
    "    res_data['timestep'] = np.concatenate(res_data['timestep'], axis=0)\n",
    "    res_data['rho'] = np.concatenate(res_data['rho'], axis=0)\n",
    "    res_data['u'] = np.concatenate(res_data['u'], axis=0)\n",
    "    return res_data\n",
    "\n",
    "def read_data_and_downsample(factor=4):\n",
    "    res_data = {\n",
    "        'timestep':[],\n",
    "        'rho':[],\n",
    "        'u':[]\n",
    "    }\n",
    "    total_batch = 1\n",
    "    for i in tqdm(range(total_batch)):\n",
    "        loaded_data = np.load('./data/ref_data_{}.npz'.format(i))\n",
    "        res_data['timestep'].append(loaded_data['timestep'])\n",
    "        res_data['rho'].append(resample_field(loaded_data['rho'], factor))\n",
    "        res_data['u'].append(resample_field(loaded_data['u'], factor))\n",
    "    res_data['timestep'] = np.concatenate(res_data['timestep'], axis=0)\n",
    "    res_data['rho'] = np.concatenate(res_data['rho'], axis=0)\n",
    "    res_data['u'] = np.concatenate(res_data['u'], axis=0)\n",
    "    return res_data"
   ],
   "id": "303bd2a9d630a5db",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:10:30.531360Z",
     "start_time": "2024-06-18T07:10:29.949690Z"
    }
   },
   "cell_type": "code",
   "source": "d = read_data_and_downsample()",
   "id": "3a2816f1434bd7b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:11:02.082614Z",
     "start_time": "2024-06-18T07:11:02.079873Z"
    }
   },
   "cell_type": "code",
   "source": "d['u'].shape",
   "id": "b7f7555340b91b76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 1760, 328, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
