{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:46:34.383142Z",
     "start_time": "2024-06-18T07:46:32.717351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax\n",
    "from jax.experimental.multihost_utils import process_allgather\n",
    "from termcolor import colored\n",
    "from src.base import LBMExternalForce, LBMBase\n",
    "from src.utils import *\n",
    "from src.boundary_conditions import *\n",
    "from src.models import BGKSim, KBCSim\n",
    "from src.lattice import LatticeD2Q9\n",
    "import jaxlib\n",
    "# Use 8 CPU devices\n",
    "# os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "jax.config.update('jax_enable_x64', True)\n"
   ],
   "id": "5f01967c372d1b78",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-18T07:46:34.389285Z",
     "start_time": "2024-06-18T07:46:34.383918Z"
    }
   },
   "source": [
    "class Cylinder(BGKSim):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def set_boundary_conditions(self):\n",
    "        # Define the cylinder surface\n",
    "        coord = np.array([(i, j) for i in range(self.nx) for j in range(self.ny)])\n",
    "        xx, yy = coord[:, 0], coord[:, 1]\n",
    "        cx, cy = 2.*_diam, 2.*_diam\n",
    "        cylinder = (xx - cx)**2 + (yy-cy)**2 <= (_diam/2.)**2\n",
    "        cylinder = coord[cylinder]\n",
    "        implicit_distance = np.reshape((xx - cx)**2 + (yy-cy)**2 - (_diam/2.)**2, (self.nx, self.ny))\n",
    "        self.BCs.append(InterpolatedBounceBackBouzidi(tuple(cylinder.T), implicit_distance, self.gridInfo, self.precisionPolicy))\n",
    "\n",
    "        # Outflow BC\n",
    "        outlet = self.boundingBoxIndices['right']\n",
    "        rho_outlet = np.ones((outlet.shape[0], 1), dtype=self.precisionPolicy.compute_dtype)\n",
    "        self.BCs.append(ExtrapolationOutflow(tuple(outlet.T), self.gridInfo, self.precisionPolicy))\n",
    "        # self.BCs.append(ZouHe(tuple(outlet.T), self.gridInfo, self.precisionPolicy, 'pressure', rho_outlet))\n",
    "\n",
    "        # Inlet BC\n",
    "        inlet = self.boundingBoxIndices['left']\n",
    "        rho_inlet = np.ones((inlet.shape[0], 1), dtype=self.precisionPolicy.compute_dtype)\n",
    "        vel_inlet = np.zeros(inlet.shape, dtype=self.precisionPolicy.compute_dtype)\n",
    "        yy_inlet = yy.reshape(self.nx, self.ny)[tuple(inlet.T)]\n",
    "        vel_inlet[:, 0] = poiseuille_profile(yy_inlet,\n",
    "                                             yy_inlet.min(),\n",
    "                                             yy_inlet.max()-yy_inlet.min(), 3.0 / 2.0 * _prescribed_vel)\n",
    "        self.BCs.append(Regularized(tuple(inlet.T), self.gridInfo, self.precisionPolicy, 'velocity', vel_inlet))\n",
    "\n",
    "        # No-slip BC for top and bottom\n",
    "        wall = np.concatenate([self.boundingBoxIndices['top'], self.boundingBoxIndices['bottom']])\n",
    "        vel_wall = np.zeros(wall.shape, dtype=self.precisionPolicy.compute_dtype)\n",
    "        self.BCs.append(Regularized(tuple(wall.T), self.gridInfo, self.precisionPolicy, 'velocity', vel_wall))\n",
    "\n",
    "    def output_data(self, **kwargs):\n",
    "        self.saved_data.append({\n",
    "            'rho':process_allgather(kwargs['rho']),\n",
    "            'u':process_allgather(kwargs['u']),\n",
    "            'timestep':kwargs['timestep'],\n",
    "        })\n",
    "        # 1:-1 to remove boundary voxels (not needed for visualization when using bounce-back)\n",
    "\n",
    "# Helper function to specify a parabolic poiseuille profile\n",
    "poiseuille_profile  = lambda x,x0,d,umax: np.maximum(0.,4.*umax/(d**2)*((x-x0)*d-(x-x0)**2))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:46:34.468736Z",
     "start_time": "2024-06-18T07:46:34.390470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "  \"\"\"Defines a convolutional block with activation and normalization.\"\"\"\n",
    "  features: int\n",
    "  kernel_size: int = (3,3)\n",
    "  strides: int = 1\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs):\n",
    "    x = nn.Conv(self.features, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(inputs)\n",
    "    x = nn.BatchNorm(use_running_average=True)(x)\n",
    "    x = nn.relu(x)\n",
    "    return x\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "  \"\"\"Downsamples feature maps through convolutions and pooling.\"\"\"\n",
    "  features: int\n",
    "  pool_factor: int = 2\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = ConvBlock(self.features)(x)\n",
    "    x = ConvBlock(self.features)(x)\n",
    "    return x\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "  \"\"\"Upsamples feature maps and concatenates with features from the contracting path.\"\"\"\n",
    "  features: int\n",
    "  up_factor: int = 2\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = ConvBlock(self.features)(x)\n",
    "    x = ConvBlock(self.features)(x)\n",
    "    x = nn.ConvTranspose(self.features, kernel_size=(2, 2), strides=self.up_factor, padding='VALID')(x)\n",
    "    return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "  \"\"\"UNet architecture with contracting and expanding paths.\"\"\"\n",
    "  features_start: int = 64\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    input_shape = x.shape\n",
    "    # Contracting path\n",
    "    down1 = DownBlock(self.features_start * 2)(x)\n",
    "    down1_max_pooled = nn.max_pool(down1, window_shape=(2, 2), strides=(2, 2))\n",
    "    down2 = DownBlock(self.features_start * 4)(down1_max_pooled)\n",
    "    down2_max_pooled = nn.max_pool(down2, window_shape=(2, 2), strides=(2, 2))\n",
    "    down3 = DownBlock(self.features_start * 8)(down2_max_pooled)\n",
    "    down3_max_pooled = nn.max_pool(down3, window_shape=(2, 2), strides=(2, 2))\n",
    "    down4 = DownBlock(self.features_start * 16)(down3_max_pooled)\n",
    "    down4_max_pooled = nn.max_pool(down4, window_shape=(2, 2), strides=(2, 2))\n",
    "    \n",
    "    # Expanding path with concatenation\n",
    "    up1 = UpBlock(self.features_start * 16)(down4_max_pooled)\n",
    "    down4_sliced = jax.lax.slice(down4, (4, 4, 0),(down4.shape[0]-4, down4.shape[1]-4, down4.shape[2]))\n",
    "    up1_concatenated = jax.lax.concatenate([down4_sliced, up1], dimension=2)\n",
    "    up2 = UpBlock(self.features_start * 4)(up1_concatenated)\n",
    "    down3_sliced = jax.lax.slice(down3, (4, 4, 0), (down3.shape[0]-4, down3.shape[1]-4, down3.shape[2]))\n",
    "    up2_concatenated = jax.lax.concatenate([down3_sliced, up2], dimension=2)\n",
    "    up3 = UpBlock(self.features_start * 2)(up2_concatenated)\n",
    "    print(up3.shape)\n",
    "    return up3\n",
    "  \n",
    "class SimpleNet(nn.Module):\n",
    "    features: int = 32\n",
    "    kernel_size: int = (5, 5)\n",
    "    strides: int = 1\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # x = nn.Conv(self.features, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(x)\n",
    "        # x = nn.leaky_relu(x)\n",
    "        # x = nn.Conv(self.features, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(x)\n",
    "        # x = nn.leaky_relu(x)\n",
    "        x = nn.Conv(self.features, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "        x = nn.Dense(self.features)(x)\n",
    "        x = nn.Conv(2, kernel_size=self.kernel_size, strides=self.strides, padding='SAME')(x)\n",
    "        return x\n"
   ],
   "id": "d0bd9ac354a8c2c3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:46:37.085840Z",
     "start_time": "2024-06-18T07:46:34.469452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from clu import metrics\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "from flax import struct                # Flax dataclasses\n",
    "import optax                           # Common loss functions and optimizers\n",
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "  accuracy: metrics.Accuracy\n",
    "  loss: metrics.Average.from_output('loss')\n",
    "class TrainState(train_state.TrainState):\n",
    "  metrics: Metrics\n",
    "\n",
    "def create_train_state(module, rng, learning_rate, momentum):\n",
    "  \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "  params = module.init(rng, jnp.ones([1, 440, 82, 2]))['params'] # initialize parameters by passing a template image\n",
    "  tx = optax.sgd(learning_rate, momentum)\n",
    "  return TrainState.create(\n",
    "      apply_fn=module.apply, params=params, tx=tx,\n",
    "      metrics=Metrics.empty())\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, ref_data, low_res_lbm_solver: LBMBase):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  frame_idx = 0\n",
    "  input_frame=ref_data[frame_idx]\n",
    "  ref_frame=ref_data[frame_idx+1]\n",
    "  ts = input_frame['timestep']\n",
    "  rho = input_frame['rho']\n",
    "  u = input_frame['u']\n",
    "  f = low_res_lbm_solver.equilibrium(rho, u, False)\n",
    "  low_res_lbm_solver.run_step(ts+1, ts, f)\n",
    "  output_frame=low_res_lbm_solver.saved_data[0]\n",
    "  def loss_fn(params):\n",
    "    correction = state.apply_fn({'params': params}, low_res_lbm_solver.saved_data[0]['u'])\n",
    "    loss = optax.l2_loss(output_frame['u']+correction, ref_frame['u'])\n",
    "    return loss\n",
    "  grad_fn = jax.grad(loss_fn)\n",
    "  grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state\n",
    "\n",
    "@jax.jit\n",
    "def pred_step(state, batch):\n",
    "  return state.apply_fn({'params': state.params}, batch)\n",
    "init_rng = jax.random.key(0)\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "from tqdm import tqdm\n",
    "my_unet = SimpleNet()\n",
    "state = create_train_state(my_unet, init_rng, learning_rate, momentum)"
   ],
   "id": "643d5ef163477022",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:46:37.092375Z",
     "start_time": "2024-06-18T07:46:37.086642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BGKSimForce(LBMExternalForce):\n",
    "    \"\"\"\n",
    "    BGK simulation class.\n",
    "\n",
    "    This class implements the Bhatnagar-Gross-Krook (BGK) approximation for the collision step in the Lattice Boltzmann Method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def collision(self, f, feq, rho, u):\n",
    "        \"\"\"\n",
    "        BGK collision step for lattice.\n",
    "\n",
    "        The collision step is where the main physics of the LBM is applied. In the BGK approximation, \n",
    "        the distribution function is relaxed towards the equilibrium distribution function.\n",
    "        \"\"\"\n",
    "        fneq = f - feq\n",
    "        fout = f - self.omega * fneq\n",
    "        return self.precisionPolicy.cast_to_output(fout)\n",
    "\n",
    "class CylinderForce(BGKSimForce):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def set_boundary_conditions(self):\n",
    "        # Define the cylinder surface\n",
    "        coord = np.array([(i, j) for i in range(self.nx) for j in range(self.ny)])\n",
    "        xx, yy = coord[:, 0], coord[:, 1]\n",
    "        cx, cy = 2.*_diam, 2.*_diam\n",
    "        cylinder = (xx - cx)**2 + (yy-cy)**2 <= (_diam/2.)**2\n",
    "        cylinder = coord[cylinder]\n",
    "        implicit_distance = np.reshape((xx - cx)**2 + (yy-cy)**2 - (_diam/2.)**2, (self.nx, self.ny))\n",
    "        self.BCs.append(InterpolatedBounceBackBouzidi(tuple(cylinder.T), implicit_distance, self.gridInfo, self.precisionPolicy))\n",
    "\n",
    "        # Outflow BC\n",
    "        outlet = self.boundingBoxIndices['right']\n",
    "        rho_outlet = np.ones((outlet.shape[0], 1), dtype=self.precisionPolicy.compute_dtype)\n",
    "        self.BCs.append(ExtrapolationOutflow(tuple(outlet.T), self.gridInfo, self.precisionPolicy))\n",
    "        # self.BCs.append(ZouHe(tuple(outlet.T), self.gridInfo, self.precisionPolicy, 'pressure', rho_outlet))\n",
    "\n",
    "        # Inlet BC\n",
    "        inlet = self.boundingBoxIndices['left']\n",
    "        rho_inlet = np.ones((inlet.shape[0], 1), dtype=self.precisionPolicy.compute_dtype)\n",
    "        vel_inlet = np.zeros(inlet.shape, dtype=self.precisionPolicy.compute_dtype)\n",
    "        yy_inlet = yy.reshape(self.nx, self.ny)[tuple(inlet.T)]\n",
    "        vel_inlet[:, 0] = poiseuille_profile(yy_inlet,\n",
    "                                             yy_inlet.min(),\n",
    "                                             yy_inlet.max()-yy_inlet.min(), 3.0 / 2.0 * _prescribed_vel)\n",
    "        self.BCs.append(Regularized(tuple(inlet.T), self.gridInfo, self.precisionPolicy, 'velocity', vel_inlet))\n",
    "\n",
    "        # No-slip BC for top and bottom\n",
    "        wall = np.concatenate([self.boundingBoxIndices['top'], self.boundingBoxIndices['bottom']])\n",
    "        vel_wall = np.zeros(wall.shape, dtype=self.precisionPolicy.compute_dtype)\n",
    "        self.BCs.append(Regularized(tuple(wall.T), self.gridInfo, self.precisionPolicy, 'velocity', vel_wall))\n",
    "\n",
    "    def output_data(self, **kwargs):\n",
    "        self.saved_data.append(kwargs['u'])\n",
    "        # 1:-1 to remove boundary voxels (not needed for visualization when using bounce-back)\n",
    "    \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def get_force(self, f_postcollision, feq, rho, u):\n",
    "        return state.apply_fn({'params': state.params}, u)"
   ],
   "id": "a2c80e8ddd009680",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:46:37.100588Z",
     "start_time": "2024-06-18T07:46:37.093328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_sim_dataset(diam, t_start, t_end, output_stride, output_offset):\n",
    "    global _diam\n",
    "    global _prescribed_vel\n",
    "    _diam = diam\n",
    "    precision = 'f64/f64'\n",
    "    # diam_list = [10, 20, 30, 40, 60, 80]\n",
    "    scale_factor = 80 / diam\n",
    "    prescribed_vel = 0.003 * scale_factor\n",
    "    _prescribed_vel = prescribed_vel\n",
    "    lattice = LatticeD2Q9(precision)\n",
    "\n",
    "    nx = int(22*diam)\n",
    "    ny = int(4.1*diam)\n",
    "\n",
    "    Re = 100.0\n",
    "    visc = prescribed_vel * diam / Re\n",
    "    omega = 1.0 / (3. * visc + 0.5)\n",
    "    kwargs = {\n",
    "        'lattice': lattice,\n",
    "        'omega': omega,\n",
    "        'nx': nx,\n",
    "        'ny': ny,\n",
    "        'nz': 0,\n",
    "        'precision': precision,\n",
    "        'return_fpost': True    # Need to retain fpost-collision for computation of lift and drag\n",
    "    }\n",
    "    # characteristic time\n",
    "    tc = prescribed_vel/diam\n",
    "    if t_end < int(100//tc):\n",
    "        print(colored(\"WARNING: timestep_end is too small, Karman flow may not appear. Recommend value is {}\".format(int(100//tc)), \"red\"))\n",
    "    sim = Cylinder(**kwargs)\n",
    "    return sim.run_batch_generator(t_end, t_start, output_offset, output_stride, generator_size=100)\n",
    "    # return sim.saved_data\n",
    "\n",
    "def generate_sim_dataset_with_profile(diam, t_start, t_end, output_stride, output_offset):\n",
    "    with jax.profiler.trace(\"/tmp/tensorboard\"):\n",
    "        generated_data = generate_sim_dataset(diam, t_start, t_end, output_stride, output_offset)\n",
    "        jax.profiler.save_device_memory_profile(\"memory.prof\")\n",
    "    return generated_data"
   ],
   "id": "33fcbd1555db15ba",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-18T07:46:43.612945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_batched_data(batched_data, seq_num):\n",
    "    output_np_data = {\n",
    "        'timestep' :[],\n",
    "        'u': [],\n",
    "        'rho': []\n",
    "    }\n",
    "    for frame in batched_data:\n",
    "        output_np_data['timestep'].append(frame['timestep'])\n",
    "        output_np_data['u'].append(frame['u'])\n",
    "        output_np_data['rho'].append(frame['rho'])\n",
    "    output_np_data['timestep'] = np.array(output_np_data['timestep'])\n",
    "    output_np_data['u'] = np.stack(output_np_data['u'], axis=0)\n",
    "    output_np_data['rho'] = np.stack(output_np_data['rho'], axis=0)\n",
    "    np.savez_compressed(\"./data/batched_ref_data_{}.npz\".format(seq_num), timestep=output_np_data['timestep'], u=output_np_data['u'], rho=output_np_data['rho'])\n",
    "    print(\"Seq {} saved\".format(seq_num))\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=24) as executor:\n",
    "    seq = 0\n",
    "    tasks = []\n",
    "    for batched_data in generate_sim_dataset(80, 0, 20000, 1, 15000):\n",
    "        tasks.append(executor.submit(process_batched_data, batched_data, seq))\n",
    "        seq += 1\n",
    "    print(\"Finishing tasks...\")\n",
    "    for task in tqdm(tasks):\n",
    "        task.result()"
   ],
   "id": "d27b5c0ba8a1ca75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mWARNING: timestep_end is too small, Karman flow may not appear. Recommend value is 2666666\u001B[0m\n",
      "\u001B[32m**** Simulation Parameters for Cylinder ****\u001B[0m\n",
      "            \u001B[34mParameter\u001B[0m | \u001B[33mValue\u001B[0m\n",
      "--------------------------------------------------\n",
      "                \u001B[34mOmega\u001B[0m | \u001B[33m1.971608832807571\u001B[0m\n",
      "     \u001B[34mGrid Points in X\u001B[0m | \u001B[33m1760\u001B[0m\n",
      "     \u001B[34mGrid Points in Y\u001B[0m | \u001B[33m328\u001B[0m\n",
      "     \u001B[34mGrid Points in Z\u001B[0m | \u001B[33m0\u001B[0m\n",
      "       \u001B[34mDimensionality\u001B[0m | \u001B[33m2\u001B[0m\n",
      "     \u001B[34mPrecision Policy\u001B[0m | \u001B[33mf64/f64\u001B[0m\n",
      "         \u001B[34mLattice Type\u001B[0m | \u001B[33mD2Q9\u001B[0m\n",
      "      \u001B[34mCheckpoint Rate\u001B[0m | \u001B[33m0\u001B[0m\n",
      " \u001B[34mCheckpoint Directory\u001B[0m | \u001B[33m./checkpoints\u001B[0m\n",
      "  \u001B[34mDownsampling Factor\u001B[0m | \u001B[33m1\u001B[0m\n",
      "      \u001B[34mPrint Info Rate\u001B[0m | \u001B[33m100\u001B[0m\n",
      "             \u001B[34mI/O Rate\u001B[0m | \u001B[33m0\u001B[0m\n",
      "        \u001B[34mCompute MLUPS\u001B[0m | \u001B[33mFalse\u001B[0m\n",
      "   \u001B[34mRestore Checkpoint\u001B[0m | \u001B[33mFalse\u001B[0m\n",
      "              \u001B[34mBackend\u001B[0m | \u001B[33mgpu\u001B[0m\n",
      "    \u001B[34mNumber of Devices\u001B[0m | \u001B[33m1\u001B[0m\n",
      "Time to create the grid mask: 0.1332082748413086\n",
      "Time to create the local masks and normal arrays: 0.8807213306427002\n",
      "WARNING: Default initial conditions assumed: density = 1, velocity = 0\n",
      "         To set explicit initial density and velocity, use self.initialize_macroscopic_fields.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 932/20001 [00:07<02:29, 127.64it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:43:35.084084Z",
     "start_time": "2024-06-18T07:43:34.969582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for task in tqdm(tasks):\n",
    "        task.result()"
   ],
   "id": "b2f70142d793ddca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:00<00:00, 34192.70it/s]\n"
     ]
    },
    {
     "ename": "ZMQError",
     "evalue": "Socket operation on non-socket",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZMQError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m tqdm(tasks):\n\u001B[0;32m----> 2\u001B[0m         \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/jax/lib/python3.11/concurrent/futures/_base.py:449\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m~/miniconda3/envs/jax/lib/python3.11/concurrent/futures/_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/jax/lib/python3.11/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "Cell \u001B[0;32mIn[7], line 15\u001B[0m, in \u001B[0;36mprocess_batched_data\u001B[0;34m(batched_data, seq_num)\u001B[0m\n\u001B[1;32m     13\u001B[0m output_np_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrho\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mstack(output_np_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrho\u001B[39m\u001B[38;5;124m'\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     14\u001B[0m np\u001B[38;5;241m.\u001B[39msavez_compressed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/batched_ref_data_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.npz\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(seq_num), timestep\u001B[38;5;241m=\u001B[39moutput_np_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestep\u001B[39m\u001B[38;5;124m'\u001B[39m], u\u001B[38;5;241m=\u001B[39moutput_np_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m], rho\u001B[38;5;241m=\u001B[39moutput_np_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrho\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeq \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m saved\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(seq_num))\n",
      "File \u001B[0;32m~/miniconda3/envs/jax/lib/python3.11/site-packages/ipykernel/iostream.py:694\u001B[0m, in \u001B[0;36mOutStream.write\u001B[0;34m(self, string)\u001B[0m\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\u001B[38;5;241m.\u001B[39mschedule(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flush)\n\u001B[1;32m    693\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 694\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_schedule_flush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(string)\n",
      "File \u001B[0;32m~/miniconda3/envs/jax/lib/python3.11/site-packages/ipykernel/iostream.py:590\u001B[0m, in \u001B[0;36mOutStream._schedule_flush\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    587\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_schedule_in_thread\u001B[39m():\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_io_loop\u001B[38;5;241m.\u001B[39mcall_later(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflush_interval, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flush)\n\u001B[0;32m--> 590\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpub_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_schedule_in_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/jax/lib/python3.11/site-packages/ipykernel/iostream.py:267\u001B[0m, in \u001B[0;36mIOPubThread.schedule\u001B[0;34m(self, f)\u001B[0m\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_events\u001B[38;5;241m.\u001B[39mappend(f)\n\u001B[1;32m    266\u001B[0m     \u001B[38;5;66;03m# wake event thread (message content is ignored)\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event_pipe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    269\u001B[0m     f()\n",
      "File \u001B[0;32m~/miniconda3/envs/jax/lib/python3.11/site-packages/zmq/sugar/socket.py:701\u001B[0m, in \u001B[0;36mSocket.send\u001B[0;34m(self, data, flags, copy, track, routing_id, group)\u001B[0m\n\u001B[1;32m    694\u001B[0m         data \u001B[38;5;241m=\u001B[39m zmq\u001B[38;5;241m.\u001B[39mFrame(\n\u001B[1;32m    695\u001B[0m             data,\n\u001B[1;32m    696\u001B[0m             track\u001B[38;5;241m=\u001B[39mtrack,\n\u001B[1;32m    697\u001B[0m             copy\u001B[38;5;241m=\u001B[39mcopy \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    698\u001B[0m             copy_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy_threshold,\n\u001B[1;32m    699\u001B[0m         )\n\u001B[1;32m    700\u001B[0m     data\u001B[38;5;241m.\u001B[39mgroup \u001B[38;5;241m=\u001B[39m group\n\u001B[0;32m--> 701\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrack\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m_zmq.py:1073\u001B[0m, in \u001B[0;36mzmq.backend.cython._zmq.Socket.send\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_zmq.py:1115\u001B[0m, in \u001B[0;36mzmq.backend.cython._zmq.Socket.send\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_zmq.py:1190\u001B[0m, in \u001B[0;36mzmq.backend.cython._zmq._check_closed\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mZMQError\u001B[0m: Socket operation on non-socket"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_data(data, imgs=20, field='u'):\n",
    "    fig, axs = plt.subplots(1, imgs, figsize=(32, 10))\n",
    "    max_val = data[0]['u'][np.where(data[0]['u'] == data[0]['u'].max())]\n",
    "    min_val = data[0]['u'][np.where(data[0]['u'] == data[0]['u'].min())]\n",
    "    for i in range(imgs):\n",
    "        img = (data[i*(len(data)//imgs)][field] - min_val)/(max_val - min_val)\n",
    "        img = np.concatenate((img, np.zeros((img.shape[0], img.shape[1], 1))), axis=2)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].set_title(\"T={}\".format(data[i*(len(data)//imgs)]['timestep']))\n",
    "def inspect_data(data):\n",
    "    print(colored(\"*** Data Summary ***\", \"red\"))\n",
    "    if len(data)==1:\n",
    "        print(colored(\"Single frame at timestep: {}\".format(data[0]['timestep']), \"green\"))\n",
    "        return\n",
    "    else:\n",
    "        print(colored(\"Timestep: first frame at T={} - last frame at T={}\".format(data[0]['timestep'], data[-1]['timestep']), 'blue'))\n",
    "        print(colored(\"Timestep stride: {}\".format(data[1]['timestep']-data[0]['timestep']), 'blue'))\n",
    "    print(colored(\"Frame attributes:\", 'blue'))\n",
    "    for i in data[0].keys():\n",
    "        print(colored('\\t{}'.format(i), 'green'), end=\" \")\n",
    "        if data[0][i] is None:\n",
    "            print(None)\n",
    "        elif type(data[0][i])==np.ndarray:\n",
    "            print(\"numpy array shape: {}\".format(data[0][i].shape))\n",
    "        elif type(data[0][i])==jaxlib.xla_extension.ArrayImpl:\n",
    "            print(\"jax array shape: {}\".format(data[0][i].shape))\n",
    "        elif type(data[0][i])==int:\n",
    "            print(\"int\")\n",
    "        else:\n",
    "            print(type(data[0][i]))\n",
    "def read_data():\n",
    "    res_data = {\n",
    "        'timestep':[],\n",
    "        'rho':[],\n",
    "        'u':[]\n",
    "    }\n",
    "    total_batch = 1\n",
    "    for i in tqdm(range(total_batch)):\n",
    "        loaded_data = np.load('./data/ref_data_{}.npz'.format(i))\n",
    "        res_data['timestep'].append(loaded_data['timestep'])\n",
    "        res_data['rho'].append(loaded_data['rho'])\n",
    "        res_data['u'].append(loaded_data['u'])\n",
    "    res_data['timestep'] = np.concatenate(res_data['timestep'], axis=0)\n",
    "    res_data['rho'] = np.concatenate(res_data['rho'], axis=0)\n",
    "    res_data['u'] = np.concatenate(res_data['u'], axis=0)\n",
    "    return res_data\n",
    "\n",
    "def read_data_and_downsample(factor=4):\n",
    "    res_data = {\n",
    "        'timestep':[],\n",
    "        'rho':[],\n",
    "        'u':[]\n",
    "    }\n",
    "    total_batch = 1\n",
    "    for i in tqdm(range(total_batch)):\n",
    "        loaded_data = np.load('./data/ref_data_{}.npz'.format(i))\n",
    "        res_data['timestep'].append(loaded_data['timestep'])\n",
    "        res_data['rho'].append(resample_field(loaded_data['rho'], factor))\n",
    "        res_data['u'].append(resample_field(loaded_data['u'], factor))\n",
    "    res_data['timestep'] = np.concatenate(res_data['timestep'], axis=0)\n",
    "    res_data['rho'] = np.concatenate(res_data['rho'], axis=0)\n",
    "    res_data['u'] = np.concatenate(res_data['u'], axis=0)\n",
    "    return res_data"
   ],
   "id": "303bd2a9d630a5db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "d = read_data_and_downsample()",
   "id": "3a2816f1434bd7b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "d['u'].shape",
   "id": "b7f7555340b91b76",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
